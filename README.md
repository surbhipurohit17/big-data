Name:- Surbhi Purohit

Student ID:- 1158953

Email ID:- spurohit@lakeheadu.ca


# ASSESING PRIVACY AND SECURITY IN BIGDATA


## Table of Contents

1. Abstract
2. Introduction
3. Methods and Investigation
4. Results
5. Conclusion



## Abstract

Big data is a term used to refer to very large data sets with more diverse and complex structures. These features are usually associated with additional difficulties in storing, analyzing, and applying for additional programs or extracting results. The term big data analysis is used to describe the process of investigating large amounts of complex data to reveal hidden patterns or identify secret associations. However, there are obvious contradictions between the security and privacy of big data and its widespread use. This document focuses on privacy and security issues in big data, the difference between privacy and security, and privacy requirements in big data. Big data has been emerging a developing interest in both scientific and industrial fields for its expected worth. However, before utilizing big data technology in massive applications, a simple but also principle topic ought to be explored: security and privacy. More and more people, devices, and sensors are generating, sharing, and communicating data through the global internet. Analyzing these data can help organizations develop new products, improve efficiency and effectiveness, and make better decisions. This report outlines the challenges of using big data in a safe, compliant, and ethical manner, and how addressing these challenges requires a data- centric security approach as well as the recent research and development on security and privacy in big data is surveyed.


## Introduction

Big data is a field that deals with analytical methods, systematically extracting information, or otherwise dealing with large or complex data sets that cannot be handled by traditional data processing applications. . Data with multiple fields (columns) provide greater statistical power, while data with greater complexity (more attributes or columns) can result in a higher rate of false discoveries. [2] Big data analytics challenges include data capture, data storage, data analysis, search, sharing, transmission, display, query, update, information privacy and data sources. Big Data was initially associated with three key concepts: capacity, diversity, and speed. Big data analysis presents challenges for sampling, so previously only observation and sampling were allowed. Therefore, big data usually includes data whose size exceeds the processing capacity of traditional software in an acceptable time and value.
Big data explicitly alludes to data sets that are so huge or complex that traditional data processing applications are not adequate. It’s the enormous volume of data—both structured and unstructured—that immerses a business on a day-to-day basis. Due to current technological development, the amount of data generated by the internet, social networking sites, healthcare applications, and many other companies, is dramatically expanding day by day. All the tremendous amount of data produced from various sources in multiple formats with very high speed is known as big data. The term big data is categorized as “another age of technologies and architectures,  designed  to  financially  separate value from very huge volumes of a different variety of data, by empowering high velocity capture, discovery and analysis”. We can utilize various approaches to acquire, process, store and analyse Big Data; in any case it is critical to remember that there are various characteristics to sources from which Big Data is received, such as data type, size, speed, consistency/trustworthiness, and frequency. Moreover, selection and building of a Big Data solution can be difficult due to factors like governance, security, and policies.

The term Big Data is generally utilized for large and complex datasets that cannot be managed by a certain software which is characterized via 7Vs namely as volume (data size), velocity (high speed of data), variety. (Diverse data types and sources), veracity (consistency and trustworthiness of data), and value (outputs gained from the data set).

![7VBigData](https://user-images.githubusercontent.com/76443465/130533787-bdc3820d-fda8-4d78-b907-0f90cd4c0e3c.JPG)


1) Volume : Volume is the amount of data we have; what used to be measured in gigabytes is now measured in Zettabytes (ZB) or even Yottabytes (YB). IoT (Internet of Things) is creating exponential data growth. It is expected that the amount of data will change significantly in the next few years. 
2) Variety : Variety describes one of the biggest challenges in big data. It can be unstructured and contains so many different types of data from XML to video to SMS. Organizing the data in a meaningful way is not an easy task, especially when the data itself changes rapidly.
3) Variety :  Variety describes one of the biggest challenges in big data. It can be unstructured and contains so many different types of data from XML to video to SMS. Organizing the data in a meaningful way is not an easy task, especially when the data itself changes rapidly.
4) Variability: Variability distinguishes from variety. If the meaning of data is continuosly changing it can have a huge impact on your data homogenization.
5)Veracity: Veracity is making sure the data is accurate, which means working to keep the bad data from accumulating in your systems. 
6)Visualization: Visualization is critical in today’s world. Using charts and graphs to visualize large amounts of complex data is much more effective in conveying meaning than spreadsheets and reports chock-full of numbers and formulas.
7)Value: Value is the main V as it makes sure that after all the above steps, we get sure if we are getting value from the data.


## Methods and Investigation

Big Data magnifies the security, compliance and governance challenges that apply for normal data as well as increasing the potential impact of data breaches. Analysis of Big Data can identify individuals and their preferences more accurately, but often in a way that is not transparent to the individuals concerned. Society's concerns about the use of big data have led to increasingly strict   regulations governing how organizations obtain, store, and use data. In order to meet these     compliance obligations, the organization 's implementation of good data governance and data-centric security controls are critical to how data  is acquired, stored, processed, and protected.A Data Centric approach to big data security and compliance provides a sustainable approach
that is independent of the tools and technologies used to analyze the data.

1)   Information centric security puts the data at the core of the security goals , strategies, processes and technologies.
2)   Information centric security starts with good data governance.
3)   Big  Data  must  be  protected  from  unauthorized access and use. Encryption,
tokenization  and   anonymization  are  important measures to achieve this aim.
4)   Big Data must have an owner. From creation or acquisition to use and disposal, its lifecycle must be properly managed.

The basic objectives of information centric security are to ensure:
1)    Availability: People can access the Big Data and Smart Information they need to perform their business functions at the time required without delay.
2)   Integrity: People are only able to manipulate Big
Data  (create,  modify  or  delete)  in     authorized manner.
3)   Confidentiality:  Only  authorized  individual  can access Big Data and Smart Information and these are not able to transmit data on to other unauthorized people
4)    Privacy and compliance: Big Data must be handled
in a legally compliant manner.

More and more people,  devices and sensors are generating, communicating, sharing and accessing data via the Internet. Analyzing this "big data" in "smart information", can help organizations make better decisions to improve efficiency and effectiveness. Gaining competitive advantage from data is not a new idea but, the amount of data available today and the way it is collected and analyzed has attracted increasing concerns . As a result, there are more regulations regarding its collection, processing and use. Organizations must pay attention to ensure compliance with these regulations and secure the data they use.

Many privacy protection technologies have been developed, but most of them are based on the anonymity of data. The following is a list of privacy protection technologies:
1) Randomization

Randomization is the process of adding noise to data, generally through the probability distribution [21]. Randomization is used in surveys, sentiment analysis, etc. Randomization does not require knowledge of other records in  the data. It can be applied  during data collection  and preprocessing. Randomization has no anonymization overhead. However, due to the complexity of time and the usefulness of the data we have demonstrated in the experiments described below, the application of randomization in large data sets is impossible.

2) T closeness

Another enhancement of L diversity is the proximity metric T.  If  the  distance  between  the  distributions  of  sensible attributes in a class does not exceed the threshold and all equivalence classes have proximity T, then the equivalence class is considered to have proximity T "[20]. The proximity T can be calculated for each attribute for sensitive attributes. The closeness of T can ensure that the properties are public, but the implementation of the closeness of T may not map the data correctly every time.

3) L diversity

To solve the homogeneity attack, another technology called L diversity is proposed. Based on L diversity, the sensitive attribute (disease) in each equivalence class must have well- represented L values.   Due to the diversity of data, it is impossible to achieve L diversity every time. L Diversity is also prone to biased attacks. When the overall distribution of the data is skewed towards a few equivalence classes, it is impossible to guarantee that the attributes will be revealed. For example, if all records are distributed in only three equivalence classes, the semantic closeness of these values will lead to attribute leakage. In addition, L diversity can lead to similarity attacks.

4) Cryptographic techniques

The data subject can encrypt the data before releasing it for analysis. However, it is very difficult to use traditional encryption technology to encrypt data on a large scale, and it can only be applied during data collection. Differential privacy techniques have been applied, in which some aggregate calculations of data are performed without actually sharing the input. For example, if x and y are two data items, the function F (x, y) will be calculated to obtain aggregate information from x and y without actually sharing x and y. This can be applied when x and y are executed with different parts in the case of vertical distribution. However, if the data is in one place in the custody of a single organization, differential privacy cannot be adopted. Another similar technology  called  multi-party  secure computing  has been used, but it has proven insufficient in terms of privacy protection. If encryption is applied during data analysis, data usefulness will be reduced. Therefore, encryption is not only difficult to implement, but also reduces the usefulness of the dat.

5) K-anonymity

Anonymization is the process of changing data before it is provided for data analytics , so that de-identification is not possible and will lead to K indistinguishable records if an attempt is made to de-identify by mapping the anonymized data with external data sources. K anonymity is prone to two attacks namely homogeneity attack and background knowledge attack. Achieving K anonymity  can be done by utilizing generalization or suppression. K anonymity can be optimized if no data loss occurs during the . Identity disclosure is one of the biggest privacy threats which cannot be guaranteed by K anonymity [18]. Personalized privacy is the most important facet of personal privacy.

 ### PRIVACY AND SECURITY CONCERNS IN BIG DATA
 
Information privacy is the authority of an individual or group to stop their information from becoming known to people other than those they give the information. Big data security is the aggregate term for every one of the measures and tools used to protect both the data and analytics processes from attacks, theft, or other malicious activities that could harm or negatively affect them .There is no single magic bullet that can solve the identified security and privacy challenges of big data. Traditional security solutions that are primarily dedicated to protecting a small amount of static data are not sufficient to meet the new requirements imposed  by  big  data services. You need  to understand  how  to  protect  a large  collection  of complex structured and unstructured data. Unauthorized access to this data to create new relationships, combine different data sources, and make it available to malicious users is a serious big data risk. The basic and most universal solutions include encrypting everything to ensure data security, no matter where the data is located (data centre, computer, mobile device, or otherwise). With the growth of big data and its processing speed, encryption, shielding, and tokenization are key elements in protecting sensitive data.

![Challenges-in-Big-Data-security-How-Can-Big-Data-Security-be-improved png](https://user-images.githubusercontent.com/76443465/130533914-f9882641-07bb-4593-92af-fe47b663c524.jpeg)

It is the privilege to have some control over how the personal information is collected and used.It is the act of guarding information and information assets through the utilization of technology, processes and training from: -Unauthorized access, Disclosure, Disruption, Modification, Inspection, Recording, and Destruction.

### PRIVACY THREATS 

Privacy is the ability of individuals to determine what data can be shared and adopt access control. If the data is in the public domain, then it is a threat to personal privacy because the data is in the possession of the data subject. The data holders can be social media applications, websites, mobile applications, e-commerce websites, banks, hospitals, etc. The data owners are responsible for ensuring the privacy of user data. In addition to data stored in the public domain, informed or uninformed users themselves can also lead to data breach. For example, most mobile applications seek to access our contacts, files, cameras, etc. And, without reading the privacy statement, we accept all terms and conditions, resulting in data leakage.

Some of the key privacy threats include: 


1)   Surveillance : Many organizations, including retail, e-commerce, etc., study the buying habits of their customers and try to provide various discounts and value-added services. Based on opinion data and sentiment analysis, social networking sites provide recommendations for new friends, places to visit, people to follow, etc. This is only possible if you continuously monitor customer transactions. This is a serious privacy threat because no one accepts surveillance.

2)   Disclosure : The data subject can anonymize the specific data of a specific person or organisation and hand over the data to the third party for analysis, making it impossible to identify the person. The third party can map the given information to freely available external data sources.

3)   Infrastructure Security
    ->Secure Distributed Processing of Data
    ->Security Best Actions for Non-Relational Data-Bases


4)  Data privacy
->Data Analysis through Data Mining preserving Data Privacy
->Cryptographic solutions for Data Security
->Granular Access control

5) Data Management and Integrity		
->Secure Data Storage as well as Transaction Logs
->Granular Audits 8. Data1 Provenance	

6) Reactive Security

7) End-to-End Filtration and Validation

8) Anonymity : Organizations that want to anonymize data and then use it for other purposes will find this increasingly difficult.


### PRIVACY REQUIREMENTS IN BIG DATA

Businesses and government agencies are generating and continuing to collect large amounts of data. Today's increasing focus on large amounts of data will undoubtedly create opportunities and ways to understand the process of processing such data in many different fields. However, the potential of big data comes at a price. User privacy is often at risk. Ensure compliance with privacy terms and regulations in current mining and big data analytics practices. Developers must be able to verify that their applications comply with privacy agreements and that sensitive information is kept confidential regardless of changes to the application and / or privacy regulations. To meet these challenges, determine the need for further contributions in the field of formal methods and testing procedures. A new example of privacy compliance testing  in  the four areas of the ETL process (extract, transform and load).

<img width="403" alt="elt-1" src="https://user-images.githubusercontent.com/76443465/130534068-08e241d8-841a-4796-a07e-dc31d76bbf34.png">


1) Pre‐hadoop process validation:  This  represents the data loading process. In this step, the privacy specifications characterize sensitive data fragments that can uniquely identify users or entities. The privacy clauses can also indicate what data can be stored and for how long.. Privacy terms can depict which pieces of data can be stored and for how long.
2) Map‐reduce process validation : This process changes big data assets to effectively respond to a query. Privacy terms can also indicate the minimum number of returned records required to cover individual values, in addition to restrictions on datsharing between various processes.	
3) ETL process validation Similar to step (2), warehousing rationale should be confirmed at this step to comply with privacy terms. Certain data values may be added anonymously or excluded in the  warehouse if  that shows high  probability of identifying a person.	
4) Reports testing report is another form of questions, which may have a higher visibility and wider the except of specific audiences. Privacy terms that characterize ‘purpose’ are essential to verify that confidential data is not reported.

## RESULT AND DISCUSSION

Comparing these models we obtain that :
1) No above techniques have sustainability for unstructured data, we need to try MDSBA
2) Only Randomization has a feature of Attribute preservation.
3)  Cryptographic  techniques  and  Randomization  among these are very complex to apply.
4) Cryptographic techniques has the maximum accuracy of results

It has been observed that all existing privacy protection mechanisms are with respect to structured data. More than
80% of the current data today is unstructured [29]. Therefore, the following challenges needs to be addressed :
1. Develop specific solutions to protect privacy in structured and unstructured data.
2. To    develop  robust  and  scalable  technology  to handle heterogeneous data sets on a large scale.
3. Data should be allowed to remain in its original form without any need for transformation and data analysis can be performed while ensuring privacy preservation.
4. New techniques should be developed apart from Anonymization to ensure protection against key privacy threats which incorporate identity disclosure, discrimination, surveillance etc.
5. Maximizing utility of data while ensuring data privacy.
6. Implement a vulnerability management program to detect and detach known vulnerabilities, implement and update anti-malware tools.
7. Implement strong identity and access controls.
8. Protect data to ensure authenticity of source and destination in transit.
9. Pick  data  centric  encryption  solution  wisely  to ensure that it is certified and meets your needs.

## CONCLUSION

Main Goal of Big Data Analysis Is to Obtain Useful Information from A Large Amount of Heterogeneous Data. However, Access to Large-scale Distributed Data Sets Brings Certain Privacy and Security Issues, Which I Briefly Discuss in This Document. I Also Investigated the Different Requirements for Security and Privacy of Big Data in Different Fields Such as Data Collection, Storage, Analysis, And Transmission. In Addition, I Have Reviewed Some Research on The Security and Privacy of Big Data. Based On This, I Have Concluded That It Is Very Important to Continuously Monitor Network Traffic to Quickly Detect Suspicious Behaviour. The Data That Can Be Transmitted Must Be Encrypted Using Appropriate Standards. According To the Type of Data, Users and Devices Must Have Access Rights to Use Resources, All Communications Must Be Conducted Through Secure Channels, And Personal Data Must Be Blocked Before the Data Set Is Released. Big Data Privacy and Security Is One of The Most Important Areas for Future Discussion and Research.

No specific solutions have been developed for unstructured data. Traditional data mining algorithms can be used for classification and grouping problems, but cannot be used to protect privacy, especially when it comes to personal-specific information.Governments all over the world need law enforcement to ensure personal privacy. The European Union [30] is working hard to enforce privacy protection laws. In addition to technical solutions, there is also a great need to educate people about the dangers of privacy to protect themselves from privacy leaks. One of the serious threats to privacy is smartphones. Many applications that run on our smartphones access large amounts of personal information in the form of contacts, messages, chats, and files without our knowledge. In most cases, people will not even read the privacy statement before installing any application. Therefore, there is an urgent need to educate people on the various vulnerabilities that can lead to the disclosure of private information.

## REFRENCES


1)Ducange  Pietro,  Pecori  Riccardo,  Mezzina  Paolo.  A glimpse on big data analytics in the framework of marketing strategies. Soft Comput. 2018;22(1):325–42. https://link.springer.com/article/10.1007/s00500-017-2536-4

2)Chauhan Arun, Kummamuru Krishna, Toshniwal Durga. Prediction of places of visit using tweets. Knowl Inf Syst. 2017;50(1):145–66.https://link.springer.com/article/10.1007%2Fs10115-016-0936-x

3)LeFevre K, DeWitt DJ, Ramakrishnan R. Mondrian multidimensional k-anonymity. In: Proceedings of the 22nd international  conference  (ICDE’06)  on  data  engineering,
2006. New York: ACM; 2006.

4)Samarati, Pierangela, and Latanya Sweeney. In: Protecting privacy when disclosing information: k- anonymity and its enforcement through generalization and suppression. Technical report, SRI International, 1998.

5)Sweeney Latanya. Achieving k-anonymity privacy protection using generalization and suppression. In J Uncertain Fuzziness Knowl Based Syst. 2002;10(05):571–
88. https://www.worldscientific.com/doi/abs/10.1142/S0218488
50200165X

6)Sweeney Latanya. k-Anonymity: a model for protecting privacy.  Int  J  Uncertain,  Fuzziness  Knowl  Based  Syst.
2002;10(05):557–70.
https://mathscinet.ams.org/mathscinet-getitem?mr=1948199

7)Williams R. On the complexity of optimal k-anonymity. In: Proc. 23rd ACM SIGMOD-SIGACT-SIGART symp. principles of database systems (PODS). New York: ACM;
2004.

8)Machanavajjhala A et al. L-diversity: privacy beyond k- anonymity. In: Proceedings of the 22nd international conference on data engineering (ICDE’06), 2006. Piscataway: IEEE; 2006.

9)Xiao X, Yufei T. Personalized privacy preservation. In: Proceedings of the 2006 ACM SIGMOD international conference on Management of data. New York: ACM; 2006.

10)Rubner Y, Tomasi T, Guibas LJ. The earth  mover’s distance as a metric for image retrieval. Int J Comput Vision.
2000;40(2):99–121.










 

